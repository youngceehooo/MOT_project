{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5243e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import cv2\n",
    "import torch\n",
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "import threading\n",
    "from queue import Queue\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de5a805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x1210ca8f610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义了一些命令行参数，使得你可以在运行脚本时通过命令行来传递特定的值\n",
    "flags.DEFINE_string('f', 'value', 'The explanation of this parameter')\n",
    "flags.DEFINE_string('model', 'yolo_nas_l', 'yolo_nas_l or yolo_nas_m or yolo_nas_s')\n",
    "flags.DEFINE_string('video', \"test.mp4\", 'path to input video or set to 0 for webcam')\n",
    "flags.DEFINE_string('output', \"output.mp4\", 'path to output video')\n",
    "flags.DEFINE_float('conf', 0.50, 'confidence threshhold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71da25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 主函数，从命令行参数解析参数并执行处理逻辑\n",
    "def main(_argv):\n",
    "    \n",
    "    video_cap = cv2.VideoCapture(FLAGS.video)\n",
    "    #获得帧的宽度\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    #获得帧的高度\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    #获取视频的帧率（帧每秒）\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # 初始化视频写入对象\n",
    "    #创建一个FourCC（四字符代码）对象，用于指定视频编码格式\n",
    "    #FourCC 'MP4V' 表示使用 MPEG-4 Part 2 编码，通常用于生成MP4格式的视频文件。FourCC是一种用于标识视频编码格式的标准。\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    #创建一个名为 writer 的视频写入对象它接受四个参数：\n",
    "    #FLAGS.output: 这是之前定义的命令行参数，表示输出视频的路径和文件名。\n",
    "    #fourcc: 这是上一行创建的FourCC对象，指定了视频编码格式。\n",
    "    #fps: 视频的帧率，用于指定写入的视频的帧率。\n",
    "    #(frame_width, frame_height): 这是视频帧的宽度和高度，用于指定写入的视频的分辨率。\n",
    "    writer = cv2.VideoWriter(FLAGS.output, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # 初始化 DeepSort 跟踪器\n",
    "    #max_age 是一个参数，用于指定跟踪目标的最大帧数。如果目标在超过这个帧数之后仍然没有被检测到，它将被视为已失去跟踪，从跟踪器中移除。\n",
    "    tracker = DeepSort(max_age=50)\n",
    "\n",
    "    # 检查是否可用 GPU，否则使用 CPU\n",
    "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # 加载 YOLO 模型\n",
    "    model = models.get(FLAGS.model, pretrained_weights=\"coco\").to(device)\n",
    "\n",
    "    # 加载 YOLO 模型所训练的 COCO 类别标签\n",
    "    classes_path = \"coco.names\"\n",
    "    #f.read() 读取了文件的内容，\n",
    "    #.strip() 方法去除了每行末尾的空白字符（如换行符），\n",
    "    #然后 .split(\"\\n\") 方法将文件内容按行分割成一个列表\n",
    "    with open(classes_path, \"r\") as f:\n",
    "        class_names = f.read().strip().split(\"\\n\")\n",
    "\n",
    "    # 创建一个随机颜色列表来表示每个类别\n",
    "    np.random.seed(42)  # 设置随机数种子，以确保每次运行生成的随机数相同\n",
    "    #生成随机数组，行数为目标类别数即为coco.names的行数，列数为3表示有三个颜色通道（红绿蓝），数值为0-255，每一行都是该类别颜色的RGB值\n",
    "    colors = np.random.randint(0, 255, size=(len(class_names), 3))  \n",
    "    # 在主函数内定义鼠标事件处理函数\n",
    "    selected_object_id = -1\n",
    "    pixels_per_meter = 1  # 像素与米的映射关系，示例值\n",
    "    time_interval = 0\n",
    "    # 初始化速度变量\n",
    "    velocity = 0.0\n",
    "    # 在主函数之前定义一个变量来保存截图状态和帧列表\n",
    "    capture_screenshot = False\n",
    "    frame_list = []\n",
    "    def on_mouse_click(event, x, y, flags, param):\n",
    "        nonlocal selected_object_id\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:  # 当鼠标左键点击时\n",
    "            for idx, track in enumerate(tracks):\n",
    "                ltrb = track.to_tlbr()  # 左上角和右下角坐标\n",
    "                x1, y1, x2, y2 = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "                if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                    selected_object_id = idx\n",
    "                    print(f\"Selected object with ID: {selected_object_id}\")\n",
    "                    break\n",
    "        elif event == cv2.EVENT_RBUTTONDOWN:  # 检测右键点击事件\n",
    "            nonlocal capture_screenshot\n",
    "            capture_screenshot = True\n",
    "   \n",
    "\n",
    "\n",
    "    # 初始化视频写入对象\n",
    "    fourcc_1 = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_filename = 'single.mp4'\n",
    "    output_fps = 8  # 设置输出视频的帧率\n",
    "    output_size = (frame_width, frame_height)\n",
    "    writer_1 = cv2.VideoWriter(output_filename, fourcc_1, output_fps, output_size)\n",
    "    \n",
    "    while True:\n",
    "        # 调用当前时间语句记录开始时间以计算 FPS\n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        # 从视频捕获中读取一帧，设定ret布尔值来判断是否结束循环\n",
    "        ret, frame = video_cap.read()\n",
    "        # 在这部分加入鼠标回应函数，一旦点击，ret值设置为0，跳出循环，执行接下来的循环，实现点击目标框专门跟踪某人的功能\n",
    "       \n",
    "        # 如果没有帧，说明已经到达视频末尾或鼠标选择\n",
    "        if not ret:\n",
    "            print(\"End of the video file...\")\n",
    "            break\n",
    "\n",
    "        # 对帧运行 YOLO 模型进行目标检测\n",
    "        detect = next(iter(model.predict(frame, iou=0.5, conf=FLAGS.conf)))\n",
    "\n",
    "        # 从检测结果中提取边界框坐标、置信度分数和类别标签\n",
    "        bboxes_xyxy = torch.from_numpy(detect.prediction.bboxes_xyxy).tolist()\n",
    "        confidence = torch.from_numpy(detect.prediction.confidence).tolist()\n",
    "        labels = torch.from_numpy(detect.prediction.labels).tolist()\n",
    "        \n",
    "        # 将边界框坐标和置信度分数合并为一个列表\n",
    "        concate = [sublist + [element] for sublist, element in zip(bboxes_xyxy, confidence)]\n",
    "        \n",
    "        # 将合并的列表与类别标签合并为最终的预测列表\n",
    "        final_prediction = [sublist + [element] for sublist, element in zip(concate, labels)]\n",
    "\n",
    "        # 初始化边界框和置信度列表\n",
    "        results = []\n",
    "        \n",
    "        # 遍历检测结果\n",
    "        for data in final_prediction:\n",
    "            confidence = data[4]  # 提取与检测相关的置信度\n",
    "\n",
    "            # 过滤掉置信度小于阈值的弱检测\n",
    "            if float(confidence) < FLAGS.conf:\n",
    "                continue\n",
    "\n",
    "            # 如果置信度大于阈值，将边界框绘制在帧上\n",
    "            xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "            class_id = int(data[5])\n",
    "            \n",
    "            # 将边界框（x、y、w、h）、置信度和类别 ID 添加到结果列表\n",
    "            results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "        # 使用新的检测结果更新跟踪器\n",
    "        tracks = tracker.update_tracks(results, frame=frame)\n",
    "        for idx, track in enumerate(tracks):\n",
    "            if selected_object_id != -1 and idx != selected_object_id:\n",
    "                continue\n",
    "            if selected_object_id != -1 and idx == selected_object_id:\n",
    "                # 在这里添加处理特定对象的代码\n",
    "                ltrb = track.to_ltrb()  # 获取跟踪信息\n",
    "                class_id = track.get_det_class()\n",
    "                \n",
    "\n",
    "                x1, y1, x2, y2 = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "                captured_image = frame[y1:y2, x1:x2]  # 截取图像\n",
    "                cv2.imwrite(\"captured_image.jpg\", captured_image)\n",
    "                # 删除选定对象的原有边界框和文本\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)  # 用白色绘制边界框\n",
    "                cv2.putText(frame, \"\", (x1 + 5, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)  # 清空文本\n",
    "        # 目标对象框设置为红色\n",
    "                B, G, R = 0,0,255\n",
    "\n",
    "        # 创建显示在帧上的文本\n",
    "                class_name = class_names[class_id]\n",
    "                text = f\"{track_id} - {class_name}(Selected) \"\n",
    "\n",
    "        # 在帧上绘制边界框和文本\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)\n",
    "                cv2.rectangle(frame, (x1 - 1, y1 - 20), (x1 + len(text) * 12, y1), (B, G, R), -1)\n",
    "                cv2.putText(frame, text, (x1 + 5, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "               \n",
    "        # 遍历跟踪结果\n",
    "        #for track in tracks:\n",
    "        for idx, track in enumerate(tracks):\n",
    "                # 如果跟踪未确认，忽略它\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            if selected_object_id != -1 and idx == selected_object_id:\n",
    "                continue\n",
    "\n",
    "            # 获取跟踪 ID 和边界框\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "            class_id = track.get_det_class()\n",
    "            # 如果有之前的帧，计算速度\n",
    "            if hasattr(track, 'has_previous_frame') and track.has_previous_frame:\n",
    "    # 在这里添加处理速度计算的代码\n",
    "\n",
    "                prev_ltrb = track.to_ltrb(previous=True)\n",
    "\n",
    "            # 计算像素变化\n",
    "                pixel_change_x = ltrb[0] - prev_ltrb[0]\n",
    "                pixel_change_y = ltrb[1] - prev_ltrb[1]\n",
    "\n",
    "            # 将像素变化映射到实际距离变化\n",
    "                distance_change_x = pixel_change_x / pixels_per_meter\n",
    "                distance_change_y = pixel_change_y / pixels_per_meter\n",
    "\n",
    "            # 计算速度，返回上一个帧和当前帧之间的时间差，以秒为单位\n",
    "                time_interval = track.get_time_interval()\n",
    "                if time_interval > 0:\n",
    "                    speed_x = distance_change_x / time_interval\n",
    "                    speed_y = distance_change_y / time_interval\n",
    "                    velocity= np.sqrt(speed_x**2+speed_y**2)\n",
    "                else:\n",
    "                    velocity = 0.0\n",
    "            x1, y1, x2, y2 = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "            \n",
    "            # 获取类别的颜色\n",
    "            color = colors[class_id]\n",
    "            B, G, R = int(color[0]), int(color[1]), int(color[2])\n",
    "            \n",
    "            # 创建显示在帧上的文本\n",
    "            class_name = class_names[class_id]\n",
    "            text = f\"{track_id} - {class_name}-{velocity} \"\n",
    "\n",
    "            # 在帧上绘制边界框和文本\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)\n",
    "            cv2.rectangle(frame, (x1 - 1, y1 - 20), (x1 + len(text) * 12, y1), (B, G, R), -1)\n",
    "            cv2.putText(frame, text, (x1 + 5, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # 在循环内判断是否需要截图\n",
    "        if capture_screenshot:\n",
    "        # 在选定对象框内截取图像\n",
    "            if selected_object_id != -1:\n",
    "                ltrb = tracks[selected_object_id].to_ltrb()\n",
    "                x1, y1, x2, y2 = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "                captured_image_1 = frame[y1:y2, x1:x2]  # 截取图像\n",
    "                frame_list.append(captured_image_1)  # 将图像添加到帧列表\n",
    "        # 将每一帧的图像写入视频文件\n",
    "        \n",
    "       # 在循环之前，对捕获的帧进行调整大小\n",
    "        output_frame_list = []\n",
    "        for frame_img in frame_list:\n",
    "            resized_frame = cv2.resize(frame_img, output_size)\n",
    "            output_frame_list.append(resized_frame)\n",
    "            \n",
    "\n",
    "# 将调整大小后的帧写入视频\n",
    "        for resized_frame in output_frame_list:\n",
    "            writer_1.write(resized_frame)\n",
    "        output_frame_list.clear()\n",
    "        frame_list.clear()\n",
    "\n",
    "        # 记录结束时间以计算 FPS\n",
    "        end = datetime.datetime.now()\n",
    "        \n",
    "        # 显示处理 1 帧所需时间\n",
    "        print(f\"Time to process 1 frame: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "        \n",
    "        # 计算并绘制 FPS\n",
    "        fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "        cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "        \n",
    "        cv2.namedWindow('Frame', cv2.WINDOW_NORMAL)\n",
    "        # 调整窗口大小以适应视频分辨率\n",
    "        cv2.resizeWindow(\"Frame\", frame_width, frame_height)\n",
    "        # 显示帧\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        \n",
    "        # 将帧写入输出视频文件\n",
    "        writer.write(frame)\n",
    "        cv2.setMouseCallback(\"Frame\", on_mouse_click)  # 设置鼠标事件回调函数\n",
    "       \n",
    "\n",
    "\n",
    "        # 检查是否按下 'q' 键来退出循环\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # 释放视频捕获和视频写入对象\n",
    "    video_cap.release()\n",
    "    writer.release()\n",
    "    writer_1.release()\n",
    "\n",
    "    # 关闭所有窗口\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbbcddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        #调用 absl 库的一个部分，用于运行主函数 main，并且可以处理命令行参数\n",
    "        app.run(main)\n",
    "\n",
    "    except SystemExit:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77263eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3.8.17",
   "language": "python",
   "name": "pytorch3.8.17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
